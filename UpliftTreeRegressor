import numpy as np
import pandas as pd
from metrics import uplift_at_k
# from sklearn.model_selection import train_test_split
from dataclasses import dataclass

np.seterr(divide='ignore', invalid='ignore')

@dataclass
class Node:
    """Decision tree node with uplift-specific fields."""
    n_items: int
    ATE: float
    split_feat: int
    split_threshold: float
    left: 'Node' = None
    right: 'Node' = None

@dataclass
class UpliftTreeRegressor:
    def __init__(self, max_depth=3,
                 min_samples_leaf=1000,
                 min_samples_leaf_treated=300,
                 min_samples_leaf_control=300):
        self.max_depth = max_depth
        self.min_samples_leaf = min_samples_leaf
        self.min_samples_leaf_treated = min_samples_leaf_treated
        self.min_samples_leaf_control = min_samples_leaf_control

    def fit(self, X: np.ndarray, treatment: np.ndarray, y: np.ndarray) -> 'UpliftTreeRegressor':
        self.n_features_ = X.shape[1]
        self.tree_ = self._split_node(X, treatment, y)
        return self

    def predict(self, X: np.ndarray) -> np.ndarray:
        """
        Predict uplift scores for a given set of samples.

        Parameters:
        X (np.ndarray): Input data with shape (n_samples, n_features).

        Returns:
        np.ndarray: Predicted uplift scores for each sample.
        """
        uplift_scores = []

        for sample in X:
            node = self.tree_
            while node.left is not None and node.right is not None:
                if sample[node.split_feat] <= node.split_threshold:
                    node = node.left
                else:
                    node = node.right

            uplift_scores.append(node.ATE)

        return np.array(uplift_scores)

    def find_threshold_options(self, column_values):
        unique_values = np.unique(column_values)
        if len(unique_values) > 10:
            percentiles = np.percentile(
                column_values, [3, 5, 10, 20, 30, 50, 70, 80, 90, 95, 97]
            )
        else:
            percentiles = np.percentile(unique_values, [10, 50, 90])

        threshold_options = np.unique(percentiles)
        return threshold_options

    def calculate_delta_delta_p(self, X, y, treatment, feature, threshold):
        treated_mask = (treatment == 1) & (X[:, feature] <= threshold)
        control_mask = (treatment == 0) & (X[:, feature] <= threshold)

        treated_group = y[treated_mask]
        control_group = y[control_mask]

        uplift_treated_left = np.mean(treated_group) - np.mean(control_group)

        treated_mask = (treatment == 1) & (X[:, feature] > threshold)
        control_mask = (treatment == 0) & (X[:, feature] > threshold)

        treated_group = y[treated_mask]
        control_group = y[control_mask]

        uplift_treated_right = np.mean(treated_group) - np.mean(control_group)

        delta_delta_p = np.abs(uplift_treated_left - uplift_treated_right)

        return delta_delta_p

    def _split(self, X: np.ndarray, treatment: np.ndarray, y: np.ndarray, feature: int) -> tuple[float, float]:
        best_threshold = None
        best_delta_delta_p = float('-inf')

        threshold_options = self.find_threshold_options(X[:, feature])

        for threshold in threshold_options:
            delta_delta_p = self.calculate_delta_delta_p(X, y, treatment, feature, threshold)
            if delta_delta_p > best_delta_delta_p:
                best_delta_delta_p = delta_delta_p
                best_threshold = threshold

        return best_threshold, best_delta_delta_p

    def _best_split(self, X: np.ndarray, treatment: np.ndarray, y: np.ndarray) -> tuple[int, float, float]:
        best_feature = None
        best_threshold = None
        best_delta_delta_p = float('-inf')

        for feature in range(self.n_features_):
            threshold, delta_delta_p = self._split(X=X, treatment=treatment, y=y, feature=feature)
            if delta_delta_p > best_delta_delta_p:
                left_indices = X[:, feature] <= threshold
                right_indices = X[:, feature] > threshold
                if np.sum(left_indices) < self.min_samples_leaf or np.sum(right_indices) < self.min_samples_leaf:
                    continue
                best_delta_delta_p = delta_delta_p
                best_threshold = threshold
                best_feature = feature

        return best_feature, best_threshold, best_delta_delta_p

    def _split_node(self, X: np.ndarray, treatment: np.ndarray, y: np.ndarray, depth: int = 0) -> Node:
        n_samples = len(y)
        uplift = np.abs(np.mean(y[treatment == 1]) - np.mean(y[treatment == 0]))

        node = Node(
            n_items=n_samples,
            ATE=uplift,
            split_feat=None,
            split_threshold=0,
        )

        if depth >= self.max_depth or n_samples <= self.min_samples_leaf:
            return node

        best_feature, best_threshold, best_delta_delta_p = self._best_split(X, treatment, y)

        node.split_feat = best_feature
        node.split_threshold = best_threshold

        if best_threshold is not None:
            left_mask =  (X[:, best_feature] <= best_threshold)
            right_mask = (X[:, best_feature] > best_threshold)

            X_left, treatment_left, y_left = X[left_mask], treatment[left_mask], y[left_mask]
            X_right, treatment_right, y_right = X[right_mask], treatment[right_mask], y[right_mask]

            node.left = self._split_node(X_left, treatment_left, y_left, depth + 1)
            node.right = self._split_node(X_right, treatment_right, y_right, depth + 1)

        return node

    def save_tree_to_txt(self, node, file, depth=0):
        if node is not None:
            # Print the current node
            file.write('\t' * depth + node.__class__.__name__ + '\n')
            file.write('\t' * (depth + 1) + f'n_items: {node.n_items}\n')
            file.write('\t' * (depth + 1) + f'ATE: {node.ATE}\n')
            file.write('\t' * (depth + 1) + f'split_feat: {node.split_feat}\n')
            file.write('\t' * (depth + 1) + f'split_threshold: {node.split_threshold}\n')

            if node.left is None and node.right is None:
                file.write('\t' * (depth + 1) + f'<leaf>\n')
                file.write('\t' * (depth + 2) + f'n_items: {node.n_items}\n')
                file.write('\t' * (depth + 2) + f'ATE: {node.ATE}\n')
                file.write('\t' * (depth + 2) + f'split_feat: {node.split_feat}\n')
                file.write('\t' * (depth + 2) + f'split_threshold: {node.split_threshold}\n')
            else:
                # Recursively write the left and right child nodes
                self.save_tree_to_txt(node.left, file, depth + 1)
                self.save_tree_to_txt(node.right, file, depth + 1)

# # Load data from a CSV file
# data = pd.read_csv('data/data.csv')

# # Extract features and target variables
# X_data = data.loc[:, data.columns.str.contains('feat')]
# y_data = data['target']
# treatment_data = data['treatment']

# X = X_data.values
# y = y_data.values
# treatment = treatment_data.values

# X_train, X_test, treatment_train, treatment_test, y_train, y_test = train_test_split(X, treatment, y, test_size=0.2, random_state=10)

# # Задаем комбинации параметров, которые хотим попробовать
# # max_depth_values = [3, 5, 7, 9]
# # min_samples_leaf_values = [1000, 2000, 3000, 5000, 6000, 8000]
# # min_samples_leaf_treated_values = [300, 500, 1000, 3000, 5000, 6500]
# # min_samples_leaf_control_values = [300, 500, 1000, 3000, 5000, 6500]

# max_depth_values = [3, 5, 7]
# min_samples_leaf_values = [1000, 2000, 3000]
# min_samples_leaf_treated_values = [300, 500, 1000]
# min_samples_leaf_control_values = [300, 500, 1000]

# best_uplift = float('-inf')
# best_params = {}
# best_uplift_model: UpliftTreeRegressor = None

# # Перебираем все комбинации параметров
# for max_depth in max_depth_values:
#     for min_samples_leaf in min_samples_leaf_values:
#         for min_samples_leaf_treated in min_samples_leaf_treated_values:
#             for min_samples_leaf_control in min_samples_leaf_control_values:
#                 uplift_model = UpliftTreeRegressor(
#                     max_depth=max_depth,
#                     min_samples_leaf=min_samples_leaf,
#                     min_samples_leaf_treated=min_samples_leaf_treated,
#                     min_samples_leaf_control=min_samples_leaf_control
#                 )
#                 uplift_model.fit(X_train, treatment_train, y_train)

#                 # Получаем предсказания uplift и вычисляем метрику uplift@k
#                 uplift_predictions = uplift_model.predict(X_test)
#                 metric = uplift_at_k(y_test, uplift_predictions, treatment_test, k=0.2)

#                 # Если текущая метрика лучше предыдущей, обновляем лучшие параметры
#                 if metric > best_uplift:
#                     best_uplift = metric
#                     best_params = {
#                         'max_depth': max_depth,
#                         'min_samples_leaf': min_samples_leaf,
#                         'min_samples_leaf_treated': min_samples_leaf_treated,
#                         'min_samples_leaf_control': min_samples_leaf_control
#                     }
#                     best_uplift_model = uplift_model


# # Save the tree to a text file
# with open('data/uplift_tree.txt', 'w') as file:
#     best_uplift_model.save_tree_to_txt(best_uplift_model.tree_, file)

# print(f'Best uplift@k: {best_uplift}')
# print(f'Best parameters: {best_params}')
